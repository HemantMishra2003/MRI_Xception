## User Interface
![Xception Model UI](UI/Xception_Ui2.jpeg)

## Deployment Demo
https://github.com/user-attachments/assets/1387e108-e032-4c76-8544-34be2f9b9d5b

## üß† Brain MRI PDF Report (Sample) :
![Xception AI Report](./UI/XceptionAI-Report.jpeg)


## Project Important Links :
________________________________

**Deployed Model Streamlit Link** :https://mri-xception-8cqqjkblxc5saqretu2cqx.streamlit.app/

**Dataset Link** : https://zenodo.org/records/12735692

**Trained Model Link** : :https://huggingface.co/HemantMishraDeepak/newXception/resolve/main/xception_brain_tumor_weights.weights.h5

# üß† MRI  Detection Model:
__________________________________
    This  Model is built using Deep Learning and Transfer Learning, 
    leveraging the power of the Xception Architecture, 
    (best for medical images fine details)   which is Pre-Trained 
     on large-scale image Datasets. Fine-tuning is applied 
    to adapt the model specifically for medical MRI Imaging.
    
### **üî¨ About Model**
______________________________

      This project presents an AI-based MRI Brain Tumor Detection System 
      which is trained over 6000 mri images , having 4 classes 
      designed to assist in the identification and classification 
      of brain tumors from MRI scan images.
     
- **Detects brain tumor presence from MRI scans.**
- **Classifies tumor types including.**
 
      1. Glioma Tumor
      2. Meningioma Tumor
      3. Pituitary Tumor
      4. No Tumor
  
# Model Performance Metrics :
__________________________________
     The model is evaluated across Training, Validation,
     and Independent Test datasets.
     
### Training & Validation Performance


  | **Metric**              | **Value** |
|-------------------------|-----------|
| **Training Accuracy**   | **99.40%** |
| **Training Loss**       | **0.0270** |
| **Validation Accuracy** | **96.93%** |
| **Validation Loss**     | **0.0986** |



### Training , Validation Learning Curves :
__________________________________________


    Accuracy
    1.00 |                                  __________________ Training (0.99)
    0.98 |                          _______/‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ Test (0.98)
    0.96 |                    _____/‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ Validation (0.97)
    0.94 |              _____/
    0.92 |         _____/
    0.90 |    _____/
    0.88 |___/
         +------------------------------------------------------------------
          1    4    7   10   13   16   19
                        Epochs


  ### Training , Validation Loss Curves : 
_____________________________________
    
    Loss 
    0.60 |
    0.55 | \
    0.50 |  \
    0.45 |\  \
    0.40 | \  \
    0.35 |  \  \
    0.30 |   \  \
    0.25 |    \  \
    0.20 |     \  \
    0.10 |       \  \___________ Validation ‚âà0.10
    0.03 |        \__________________________ Train ‚âà0.03
    0.05 |
         +------------------------------------------------
         1   3   5   7   9   11  13  15  17  19
                              Epochs
                              
### Classification Report Validation  Data

| Class        | Precision | Recall | F1-Score | Support |
|--------------|-----------|--------|----------|---------|
| Glioma       | 0.98      | 0.99   | 0.98     | 264     |
| Meningioma   | 0.94      | 0.98   | 0.96     | 267     |
| No Tumor     | 0.98      | 0.92   | 0.95     | 319     |
| Pituitary    | 0.97      | 0.98   | 0.98     | 291     |
| **Accuracy** |           |        | **0.97** | **1141**|


## ROC Curve

                TPR (Y)
            1.0 ‚î§‚îÇ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ---
                ‚î§‚îÇ                                         --
                ‚î§‚îÇ                                      -- 
                ‚î§‚îÇ                                  -- 
                ‚î§‚îÇ                              -- 
            0.6 ‚î§‚îÇ                          -- 
                ‚î§‚îÇ                      -- 
                ‚î§‚îÇ                  --                  
                ‚î§‚îÇ              --                                            
            0.2 ‚î§‚îÇ          --                      
                ‚î§‚îÇ    -- 
            0.0 ‚îº‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ--‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ
               0.0       0.2      0.4      0.6      0.8      1.0
                           FPR (X)



                  Glioma (AUC‚âà0.999)
                  Meningioma (AUC‚âà0.999)
                  No Tumor (AUC‚âà1.000)
                  Pituitary (AUC‚âà1.000)

- The ROC curve shows that the model achieves. 
- a very high true positive rates extremely
- low false positive rates, indicating excellent tumor
- discrimination capability.

                         
 ### Confusion Matrix  of Validation Data 
  _______________________________________


                          P R E D I C T E D
    ______________________________________________________________________
            |      Glioma |  Meningioma |   No Tumor |  Pituitary
    ______________________________________________________________________
    Actual  | Glioma      |     261     |      2     |      0     |    1
    ______________________________________________________________________
    Actual  | Meningioma  |      0      |     262    |      5     |    0
    ______________________________________________________________________
    Actual  | No Tumor    |      6      |     10     |    295    |    8
    ______________________________________________________________________
    Actual  | Pituitary   |      0      |      4     |      1     |   286
    ______________________________________________________________________

### Validation Confusion Matrix Simlification : 
 ________________________________________

    Actual ‚Üì         Predicted ‚Üì
    ------------    ----------------------
    Glioma        ‚Üí   261 correct, 3 wrong
    Meningioma    ‚Üí   262 correct, 5 wrong
    No Tumor      ‚Üí   295 correct, 24 wrong
    Pituitary     ‚Üí   286 correct, 5 wrong

    
# Test Performance
__________________________


## Test Set Performance (Unseen Data)
_________________________________________

### - **Test Accuracy** : **98.93%**
###  - **Test Precision**: **98.93%**
### - **Test Recall**   : **98.93%**

## Test Set Performance Classification Report 

| Class        | Precision | Recall | F1-Score | Support |
|--------------|-----------|--------|----------|---------|
| Glioma       | 1.0000    | 0.9967 | 0.9983   | 300     |
| Meningioma   | 0.9935    | 0.9967 | 0.9951   | 306     |
| No Tumor     | 1.0000    | 1.0000 | 1.0000   | 405     |
| Pituitary    | 0.9967    | 0.9967 | 0.9967   | 300     |

### TEST CONFUSION MATRIX

                             Predicted
     _______________‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î¨‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î¨‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î¨‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê
     Actual         ‚îÇ Glioma   ‚îÇ Meningioma ‚îÇ No Tumor ‚îÇ Pituitary  ‚îÇ
     ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îº‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îº‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îº‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îº‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î§
     Glioma         ‚îÇ   299    ‚îÇ     1      ‚îÇ    0     ‚îÇ     0      ‚îÇ
     Meningioma     ‚îÇ    0     ‚îÇ   305      ‚îÇ    0     ‚îÇ     1      ‚îÇ
     No Tumor       ‚îÇ    0     ‚îÇ     0      ‚îÇ   405    ‚îÇ     0      ‚îÇ
     Pituitary      ‚îÇ    0     ‚îÇ     1      ‚îÇ    0     ‚îÇ   299      ‚îÇ
     ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î¥‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î¥‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î¥‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î¥‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò

### Test  Confusion Matrix Simlification : 
________________________________________

    Actual ‚Üì              Predicted ‚Üì
    --------------    ----------------------
    Glioma        ‚Üí   299 correct, 1 wrong
    Meningioma    ‚Üí   305 correct, 1 wrong
    No Tumor      ‚Üí   405 correct, 0 wrong
    Pituitary     ‚Üí   299 correct, 1 wrong


### Recall Value ‚Äì Medical Interpretation (MRI Brain Tumor Detection)
_______________________________________________________________________

    This model demonstrates strong recall performance
    across all MRI brain tumor classes, with Glioma recall of 99.67%,
    Meningioma recall of 99.67%, No Tumor recall of 100.00%,
    and Pituitary tumor recall of 99.67%.

    The consistently high recall for tumor-positive classes,
    particularly Pituitary (99.67%), Meningioma (99.67%),
    and Glioma (99.67%), indicates that the model is highly sensitive
    toward detecting abnormal brain structures in MRI scans.

    In medical screening and radiological diagnostics,
    Recall is critically important, as missing a brain tumor
    (false negative) can delay treatment and significantly
    impact patient outcomes.

    Although an ideal Recall value is close to 100%,
    achieving perfect Recall in MRI-based tumor detection
    is challenging due to tumor morphology variations,
    imaging noise, inter-patient diversity, and dataset limitations.
    Despite these challenges, the proposed model achieves
    near-perfect recall across all classes on the test dataset.

Overall, the achieved Recall values suggest that the model is
well-suited for assistive clinical screening,
where prioritizing tumor detection over false alarms
is essential.

# Our Model Architecture ü´Ü
_____________________________

         ______________________           _________________________         ________________________
        |   Input MRI Image   |          |                         |       |                       |
        |   299 x 299 x 3     |--------> |    Data Augmentation    |------>|  Rescaling (1 / 255)  |
        |_____________________|          |_________________________|       |_______________________| 
                                                   |
                              _____________________v______________________________
                             |                                                     |
                             |                    Xception Network                 |
                             |     Pretrained on ImageNet (include_top = False)    |
                             |     Depthwise Separable Convolutions                |
                             |_____________________________________________________|
                                                   |
                                                   v
           ____________________________     ________________________     ______________________
          |  Global Average Pooling    |-->|      Dropout (0.3)     | -->|  Dense (128 units)  |
          |____________________________|   |________________________|    | Activation : ReLU   |
                                                                         |_____________________|             
                                                                                 |
                                                                                 v
                                                                    ______________________
                                                                   |    Dropout (0.25)    |
                                                                   |______________________|
                                                                           |
                                                                           v
                                                _________________________________________________
                                               |               Softmax Output Layer              |
                                               |     Classes : Glioma | Meningioma | No Tumor    |              
                                               |                   Pituitary                     |
                                               |_________________________________________________|
                                               

## Training Strategy (Xception) :

     ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê      ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê
     ‚îÇ   Load Xception Backbone       ‚îÇ‚îÄ‚îÄ‚îÄ‚îÄ‚ñ∂ ‚îÇ   Load ImageNet Weights        ‚îÇ
     ‚îÇ   (include_top = False)        ‚îÇ      ‚îÇ   (Pretrained Initialization)  ‚îÇ
     ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î¨‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò      ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î¨‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò
                     ‚îÇ                                       ‚îÇ
                     ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î¨‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò
                                    ‚ñº
        ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê       ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê
        ‚îÇ   Freeze Base Model            ‚îÇ‚îÄ‚îÄ‚îÄ‚îÄ‚ñ∂ |    Configure Optimizer          ‚îÇ
        ‚îÇ   (Feature Extraction Mode)    ‚îÇ       ‚îÇ   (Adamax, Initial LR)         ‚îÇ
        ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î¨‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò       ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î¨‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò
                         ‚îÇ                                       ‚îÇ
                         ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î¨‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò
                                        ‚ñº
              ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê      ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê
              ‚îÇ   Train Classifier Head        ‚îÇ‚îÄ‚îÄ‚îÄ‚îÄ‚ñ∂ ‚îÇ   Monitor Validation Metrics  ‚îÇ
              ‚îÇ   (GAP + Dense + Dropout)      ‚îÇ      ‚îÇ   (Accuracy / Loss)            ‚îÇ
              ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î¨‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò      ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î¨‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò
                              ‚îÇ                                       ‚îÇ
                              ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î¨‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò
                                             ‚ñº
              ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê
              ‚îÇ              Fine-Tuning (Unfreeze Top Layers)                 ‚îÇ
              ‚îÇ             Reduced Learning Rate for Stability                ‚îÇ
              ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î¨‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò
                                              ‚ñº
               ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê
               ‚îÇ                   Apply Training Callbacks                     ‚îÇ
               ‚îÇ               ‚Ä¢ ModelCheckpoint (Save Best Model)              ‚îÇ
               ‚îÇ               ‚Ä¢ EarlyStopping (Overfitting Control)            ‚îÇ
               ‚îÇ               ‚Ä¢ ReduceLROnPlateau (Adaptive LR)                ‚îÇ
               ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î¨‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò
                                               ‚ñº
              ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê
              ‚îÇ                  Best Xception Model Saved                     ‚îÇ
              ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò

 
                          
# Installation & Setup :
___________________________

> Follow the steps below to Run this project locally and test the Pneumonia Detection Model.

1. Clone this Repository:
   
       git clone https:https://github.com/HemantMishra2003/MRI-Xception.git
   
3. Install Python Dependencies:

       pip install -r requirements.txt
   
3. To Run the Streamlit app and test the model:
   
               streamlit run app.py
   
5. Test image for Prediction:

        Use  my given link Dataset to get Test image or  use my Assets folder
        my Assets folder to get all 4 classes  Mri  image to make prediction.
   
# How can you Contribute üôÇ
____________________________

If you would like to contribute to this Project, please follow these steps:

1. Fork the repository.
2. Create a New Branch for your feature or fix.
3. Make your changes with clear and meaningful commits.
4. Submit a Pull Request describing your changes.
   
        Suggestions for improvements, bug fixes, documentation enhancements,
                    and feature ideas are always welcome.üòä

# Model Comparison: EfficientNet-B3 vs Xception
_____________________________________________________________________

> Initially, the model was trained using EfficientNet-B3.
> where it achieved an overall test accuracy of approximately 87%.
> Although EfficientNet-B3 is a strong and lightweight architecture. 
> its performance was limited in capturing the fine-grained structural.
> variations present in MRI brain tumor images.

> To improve performance, the model was later retrained using the Xception architecture,
> which resulted in a significantly higher test accuracy of approximately 98%.
 
##  Why did Xception perform better?

    The improvement in accuracy can be attributed 
    to the architectural differences between the two models:

- Xception uses depthwise separable convolutions.
- which allow the model to learn spatial features. 
- and channel-wise features independently.
- This is particularly effective for MRI scans. 
- where subtle texture and boundary differences are critical.

- Brain tumor classes often share similar visual patterns, 
- and Xception is better at capturing fine-grained tumor 
- morphology compared to EfficientNet-B3.

- EfficientNet-B3 is optimized for parameter efficiency.
- and general-purpose image classification, 
- whereas Xception provides stronger feature disentanglement,
- making it more suitable for medical imaging tasks.

- The improved feature extraction capability of Xception led to better.
- class separation, resulting in higher accuracy and more reliable predictions.

       THAT  TARINED FILE IS AVAILABLE IN THIS REPO AND THEIR MATRICS TOO
        

# Thanks Section üôè
 _____________________
   
         Thanks to my super senior Vishwas Mishra(Rolls Royce), who keeps motivating me
                   and continuously helps me to improve my skills.‚Äù ‚ù§Ô∏è

     
      
